# TuyaBOT LLM ü§ñÔ∏èÔ∏èÔ∏èÔ∏è

Creator: John Mario Montoya Zapata üë®‚Äçüíª

## Version history:
| User                      | Version | date       |
|---------------------------|---------|------------|
| John Mario Montoya Zapata | 0.1.0   | 2025-02-28 |
|                           |         |            |

## Description üìö
TuyaBot-LLM is a chatbot based on a [RAG](https://www.databricks.com/glossary/retrieval-augmented-generation-rag) architecture, which uses an large language model (LLM), the [unsloth/Llama-3.2-1B-Instruct](https://huggingface.co/unsloth/Llama-3.2-1B-Instruct) from meta, and the web information available from the financial company [TUYA S.A](https://www.tuya.com.co/yo-tengo) to answer questions related to its products and services.

## Table of contents üìã
1. [Demo: How to interact with the local LLM](#model-for-default-prediction-block-diagram)
2. [How reproduce in your local machine](#how-reproduce-in-your-local-machine)
3. [Repository structure](#repository-structure)
4. [Cloning this repository](#cloning-this-repository)
5. [Setting up a virtual environment](#setting-up-a-virtual-environment)

## Demo: How to interact with the local LLM ü§ñÔ∏èÔ∏èÔ∏èÔ∏è

![GIF DEMO](/reports/figures/demo-gif-ezgif.com-crop.gif)


## How reproduce in your local machine
The device tested on is an HP Victus with the following specifications:

- Processor 12th Gen Intel(R) Core(TM) i5-12500H 2.50 GHz
- Installed RAM 16.0 GB (15.7 GB usable)
- Installed GPU NVIDIA GFORCE RTX 3050 4.0 GB

1. [Clone the repository](#cloning-this-repository)
2. [Create a virtual environment](#setting-up-a-virtual-environment) and activate it
3. Install dependencies: In bash, use the next commands, Be careful, your GPU shoul support cuda 12.6. [Here](https://pytorch.org/get-started/locally/) to get more information. Otherwise, the model will be installed on CPU.

```bash
pip install -r requirements.txt
```
```bash
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu126
```
4. In parent directory run the next command to get the base information
```bash
python main.py make_data
```
5. Run application using the next command
```bash
python app.py
```

## Repository structure. üóÇÔ∏è

This project structure was partially influenced by the [Cookiecutter Data Science project](https://drivendata.github.io/cookiecutter-data-science/) and [reproducible-model](https://github.com/cmawer/reproducible-model) repository.

Check this [post](https://www.jeremyjordan.me/ml-projects-guide/) by Jeremy Jordan for get guidelines on managing ML projects.

Other resources.
- Books
    - [Clean Machine Learning Code](https://leanpub.com/cleanmachinelearningcode)

```
‚îú‚îÄ‚îÄ LICENSE
|
‚îú‚îÄ‚îÄ README.md                        <- You are here
|
‚îú‚îÄ‚îÄ app/                             <- Folder to store the API that exposes the model
|
‚îú‚îÄ‚îÄ credentials/                     <- Folder to store credentials files
|
‚îú‚îÄ‚îÄ data/                            <- Folder that contains data used or generated
‚îÇ¬†¬† ‚îú‚îÄ‚îÄ external/                    <- Data from third parties (external to the core company of the project)
‚îÇ¬†¬† ‚îú‚îÄ‚îÄ interim/                     <- Data in an intermediate state of processing
‚îÇ¬†¬† ‚îú‚îÄ‚îÄ processed/                   <- Data fully processed and ready to be used in modeling
‚îÇ¬†¬† ‚îî‚îÄ‚îÄ raw/                         <- The original, immutable data dump
|
‚îú‚îÄ‚îÄ docs/                            <- A default Sphinx project; see sphinx-doc.org for details
|
‚îú‚îÄ‚îÄ models/                          <- Trained and serialized models, model predictions, or model summaries
‚îÇ¬†¬† ‚îî‚îÄ‚îÄ mlruns/                      <- Folder to store trained, serialized and tracked models using the MLflow library
|
‚îú‚îÄ‚îÄ notebooks/                       <- Jupyter notebooks. Naming convention is a number (for ordering),
‚îÇ                                       the creator's initials, and a short `-` delimited description, e.g.
‚îÇ                                       `101-jmmz-initial-data-exploration.ipynb`.
|
‚îú‚îÄ‚îÄ references/                      <- Data dictionaries, manuals, and all other explanatory materials
|
‚îú‚îÄ‚îÄ reports/                         <- Generated analysis as HTML, PDF, LaTeX, etc
‚îÇ¬†¬† ‚îú‚îÄ‚îÄ figures/                     <- Generated graphics and figures to be used in reporting
‚îÇ¬†¬† ‚îú‚îÄ‚îÄ pdfs/                        <- PDF files for reporting
‚îÇ¬†¬† ‚îî‚îÄ‚îÄ logs/                        <- Store some flat file reports concerning the execution of commands by terminal mainly
|
‚îú‚îÄ‚îÄ tuyabot_llm/             <- Source code for use in this project
‚îÇ¬†¬† ‚îú‚îÄ‚îÄ __init__.py                  <- Makes src a Python module
‚îÇ¬†¬† ‚îú‚îÄ‚îÄ archive/                     <- Old scripts that are removed by restructuring the code. They are kept for future reference
‚îÇ¬†¬† ‚îú‚îÄ‚îÄ data/                        <- Scripts to generate, obtain, clean or load raw data
‚îÇ¬†¬† ‚îú‚îÄ‚îÄ features/                    <- Scripts to turn data into features for modeling
‚îÇ¬†¬† ‚îú‚îÄ‚îÄ models/                      <- Scripts to use trained models to make predictions and to retrain models
‚îÇ¬†¬† ‚îú‚îÄ‚îÄ performance/                 <- Scripts to evaluate the performance of models and to calculate metrics from the trained model 
‚îÇ¬†¬† ‚îú‚îÄ‚îÄ visualization/               <- Scripts to generate evaluation graphs or reports 
‚îÇ¬†¬† ‚îî‚îÄ‚îÄ utils/
‚îÇ¬†¬†    ‚îú‚îÄ‚îÄ __init__.py
‚îÇ¬†¬†    ‚îî‚îÄ‚îÄ absolute_paths.py         <- Module for handling absolute path
‚îÇ
‚îú‚îÄ‚îÄ queries/                         <- Folder to store .sql files used at some point in the modeling process   
‚îÇ¬†¬† ‚îú‚îÄ‚îÄ develop/                     <- Queries created in bulding process 
‚îÇ¬†¬† ‚îî‚îÄ‚îÄ production/                  <- Clean queries used to production
|
‚îú‚îÄ‚îÄ environment.yml                  <- The environment file for reproducing the analysis environment, e.g.
‚îÇ                                        generated with `conda env export --from-history --file environment.yml`
|
‚îú‚îÄ‚îÄ requirements.txt                 <- The requirements file for reproducing the analysis environment, e.g.
‚îÇ                                        generated with `pip freeze > requirements.txt`
|
‚îú‚îÄ‚îÄ .gitignore                       <- Gitignore file 
|
‚îú‚îÄ‚îÄ install.md                       <- Instructions to configure virtual environments and install the package as a distributable 
|
‚îú‚îÄ‚îÄ app.py                           <- Application running with Gradio locally
|
‚îú‚îÄ‚îÄ main.py                          <- Main file to orchestrate re-trains and execution of source code stored in src folder
|
‚îú‚îÄ‚îÄ main.ipynb                       <- Like main.py but intended for testing before launching deployments
|
‚îú‚îÄ‚îÄ setup.py                         <- Defines project metadata, dependencies, and installation requirements for distribution.
|
‚îî‚îÄ‚îÄ run.sh                           <- Executable with predefined commands to run main.py file on a remote server
```

## Cloning this repository.

- To clone this repository using SSH run the next command in your git console
> `git clone git@github.com:johnma96/tuyabot-llm.git`
- To clone this repository using HTTPS run the next command in your git console
> `git clone https://github.com/johnma96/tuyabot-llm.git`

For more details see [Clone a repository](https://docs.gitlab.com/ee/gitlab-basics/start-using-git.html#clone-a-repository).

## Setting up a virtual environment.

In order to not create conflics between your libraries and the requirements libraries for this project, we highly recomend you to create a new virtual environment to install the requirements libraries in there.

**Check out the installation guide [here](/install.md)**

For more details consult:
- Click [here](https://docs.python.org/3/library/venv.html) to see how to create a virtual environment in python.
- Click [here](https://conda.io/projects/conda/en/latest/user-guide/tasks/manage-environments.html) if you are using conda.

### Installing and updating project libraries.
The required libraries are listed in the file [`requirements.txt`](/requirements.txt) or [`environment.yml`](/environment.yml). **Please read [the installation guide](/install.md) information for greater detail.**