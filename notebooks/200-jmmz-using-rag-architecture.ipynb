{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use this initial code to work in the notebook as if it were a module, that \n",
    "# is, to be able to export classes and functions from other subpackages.\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "package_path = os.path.abspath('.').split(os.sep + 'notebooks')[0]\n",
    "if package_path not in sys.path:\n",
    "    sys.path.append(package_path)\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from dotenv import load_dotenv\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from tuyabot_llm import AbsolutePaths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables from .env\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get information from web pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Step 1: Scrape the content from apple.com using WebBaseLoader\n",
    "urls = [\n",
    "        \"https://www.tuya.com.co/como-pago-mi-tarjeta-o-credicompras\", \n",
    "        \"https://www.tuya.com.co/tarjetas-de-credito\", \n",
    "        \"https://www.tuya.com.co/credicompras\", \n",
    "        \"https://www.tuya.com.co/otras-soluciones-financieras\", \n",
    "        \"https://www.tuya.com.co/nuestra-compania\", \n",
    "        \"https://www.tuya.com.co/activacion-tarjeta\"\n",
    "]\n",
    "\n",
    "# Create a loader for web content\n",
    "loader = WebBaseLoader(urls)\n",
    "documents = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents[0].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(documents[1].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import nltk\n",
    "# from nltk.corpus import stopwords\n",
    "# from nltk.tokenize import word_tokenize\n",
    "\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('stopwords')\n",
    "\n",
    "# for document in documents:\n",
    "#     tokens = word_tokenize(document.page_content)\n",
    "#     stop_words = set(stopwords.words('spanish'))\n",
    "#     tokens = [token for token in tokens if token.lower() not in stop_words]\n",
    "#     document.page_content = ' '.join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents[0].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for document in documents:\n",
    "    document.page_content = document.page_content.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(documents[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for document in documents:\n",
    "    document.page_content = document.page_content.strip()\n",
    "    document.page_content = document.page_content.replace('\\n', ' ').replace('\\r', ' ').replace('\\t', ' ')\n",
    "    document.page_content = ' '.join(document.page_content.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents[1].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(documents[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chunk files and create embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chunk files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=700,\n",
    "    chunk_overlap=5,\n",
    "    length_function=len\n",
    ")\n",
    "docs = text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import SentenceTransformerEmbeddings\n",
    "\n",
    "embeddings = SentenceTransformerEmbeddings(model_name=\"all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create vector database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the persistent directory\n",
    "current_dir = AbsolutePaths().get_abs_path_folder('raw')\n",
    "db_dir = os.path.join(current_dir, \"tuya_collection\")\n",
    "persistent_directory = os.path.join(db_dir, \"chroma_tuya_collection\")\n",
    "\n",
    "# Step 4: Create and persist the vector store with the embeddings\n",
    "if not os.path.exists(persistent_directory):\n",
    "    print(f\"\\n--- Creating vector store in {persistent_directory} ---\")\n",
    "    db = Chroma.from_documents(docs, embeddings, persist_directory=persistent_directory)\n",
    "    print(f\"--- Finished creating vector store in {persistent_directory} ---\")\n",
    "else:\n",
    "    # print(f\"Vector store {persistent_directory} already exists. No need to initialize.\")\n",
    "    # db = Chroma(persist_directory=persistent_directory, embedding_function=embeddings)\n",
    "\n",
    "    print(f\"\\n--- Creating vector store in {persistent_directory} ---\")\n",
    "    db = Chroma.from_documents(docs, embeddings, persist_directory=persistent_directory)\n",
    "    print(f\"--- Finished creating vector store in {persistent_directory} ---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrive documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Query the vector store\n",
    "retriever = db.as_retriever(\n",
    "    search_type=\"similarity\",\n",
    "    search_kwargs={\"k\": 10},\n",
    ")\n",
    "\n",
    "# Define the user's question\n",
    "query = \"¿Cuáles son los valores la tasa de interés y póliza del producto credicompras?\"\n",
    "\n",
    "# Retrieve relevant documents based on the query\n",
    "relevant_docs = retriever.invoke(query)\n",
    "\n",
    "# Display the relevant results with metadata\n",
    "print(\"\\n--- Relevant Documents ---\")\n",
    "for i, doc in enumerate(relevant_docs, 1):\n",
    "    print(f\"Document {i}:\\n{doc.page_content}\\n\")\n",
    "    if doc.metadata:\n",
    "        print(f\"Source: {doc.metadata.get('source', 'Unknown')}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relevant_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_docs(docs):\n",
    "    formatted_docs = \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "    # print(f\"**Formatted Docs**: {formatted_docs}\\n*******************************\")  # Inspeccionar la salida de format_docs\n",
    "    return formatted_docs\n",
    "\n",
    "context = format_docs(relevant_docs)  # Aplica el formateo a los documentos recuperados\n",
    "print(\"Context for LLM:\", context)  # Ver el contexto final que se pasará al modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA está disponible. El modelo puede ejecutarse en GPU.\")\n",
    "else:\n",
    "    print(\"CUDA no está disponible. El modelo se ejecutará en CPU.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_default_tensor_type(\"torch.cuda.FloatTensor\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline \n",
    "from langchain_huggingface import HuggingFacePipeline\n",
    "\n",
    "model_id = 'unsloth/Llama-3.2-1B-Instruct' \n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id, device=\"cuda:0\", truncation=True)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id) \n",
    "\n",
    "\n",
    "pipe = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    max_length=2000,\n",
    "    # truncate=True,\n",
    "    temperature=0.1,\n",
    "    top_k=10,\n",
    "    # repetition_penalty=1.5,\n",
    "    # no_repeat_ngram_size=4,  # Ajusta el tamaño de los n-gramas que no se pueden repetir\n",
    ")\n",
    "\n",
    "#conversión a uso api tipo langchain \n",
    "local_llm = HuggingFacePipeline(pipeline=pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verifica la salida generada\n",
    "# prompt = \"Dime un chiste\"\n",
    "# response = local_llm(prompt)\n",
    "# print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use RAG architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "template = \"\"\"\n",
    "Eres un agente de servicio al cliente que trabaja para TUYA SA, una empresa que se\n",
    "dedica a ser la solución financiera del retail y que busca apoyar a los sectores\n",
    "vulnerables de la sociedad. \n",
    "\n",
    "Como agente de servicio al cliente, debes suministrar respuestas amigables y\n",
    "claras a los clientes.\n",
    "\n",
    "Emplea el contexto que te ofrece la empresa TUYA delimitado por triple comillas invertidas, para responder\n",
    "la pregunta que se encuentra al final delimitada por comillas simples.\n",
    "\n",
    "Siempre que puedas responder con una serie de items hazlo, tu respuesta es máximo de 15 palabras.\n",
    "\n",
    "Contexto: ```{context}```\n",
    "\n",
    "Pregunta: '{question}'\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "\n",
    "rag_chain = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | local_llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"Cuáles son los productos financieros de Tuya?\"\n",
    "rag_chain.invoke(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = \"\"\"\n",
    "¿Cuáles son los valores de la tasa de interés y póliza del producto credicompras?\n",
    "\"\"\"\n",
    "for chunk in rag_chain.stream(q):\n",
    "    print(chunk, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = \"\"\"\n",
    "¿Cuáles son los nombres de las tarjetas de crédito que tiene disponible Tuya?\n",
    "\"\"\"\n",
    "for chunk in rag_chain.stream(q):\n",
    "    print(chunk, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo to deploy sing gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir la función para generar la respuesta\n",
    "def generate_response(question):\n",
    "\n",
    "    template = \"\"\"\n",
    "        Eres un agente de servicio al cliente que trabaja para TUYA SA, una empresa que se\n",
    "        dedica a ser la solución financiera del retail y que busca apoyar a los sectores\n",
    "        vulnerables de la sociedad. \n",
    "\n",
    "        Como agente de servicio al cliente, debes suministrar respuestas amigables y\n",
    "        claras a los clientes.\n",
    "\n",
    "        Emplea el contexto que te ofrece la empresa TUYA delimitado por triple comillas invertidas, para responder\n",
    "        la pregunta que se encuentra al final delimitada por comillas simples.\n",
    "\n",
    "        Siempre que puedas responder con una serie de items hazlo, tu respuesta es máximo de 15 palabras.\n",
    "\n",
    "        El formato de la respuesta corresponde a:\n",
    "\n",
    "        TuyaBot: Tu respuesta va aquí\n",
    "\n",
    "        Contexto: ```{context}```\n",
    "\n",
    "        Pregunta: '{question}'\n",
    "        \"\"\"\n",
    "    \n",
    "    prompt = PromptTemplate.from_template(template)\n",
    "\n",
    "    rag_chain = (\n",
    "        {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "        | prompt\n",
    "        | local_llm\n",
    "        | StrOutputParser()\n",
    "    )\n",
    "\n",
    "    output = rag_chain.invoke(question)\n",
    "\n",
    "    \n",
    "    return  output\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"Cuáles son los productos financieros de Tuya?\"\n",
    "generate_response(question=question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "* Running on public URL: https://9c6aa976169f91efcf.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://9c6aa976169f91efcf.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "\n",
    "# Crear la interfaz de Gradio\n",
    "demo = gr.Interface(\n",
    "    fn=generate_response,\n",
    "    inputs=[\n",
    "        gr.Textbox(label=\"question\"),\n",
    "    ],\n",
    "    outputs=gr.Textbox(label=\"answer\"),\n",
    "    title=\"Agente de Servicio al Cliente TUYABOT\",\n",
    "    description=\"Pregúntame algo sobre TUYA SA\",\n",
    ")\n",
    "\n",
    "# Desplegar la interfaz\n",
    "demo.launch(share=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing server running on port: 7860\n"
     ]
    }
   ],
   "source": [
    "demo.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
