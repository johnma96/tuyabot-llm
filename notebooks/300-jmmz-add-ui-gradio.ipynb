{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# Load Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use this initial code to work in the notebook as if it were a module, that \n",
    "# is, to be able to export classes and functions from other subpackages.\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "package_path = os.path.abspath('.').split(os.sep + 'notebooks')[0]\n",
    "if package_path not in sys.path:\n",
    "    sys.path.append(package_path)\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mario\\Documents\\job_interviews\\2025_tuya\\tuyabot_llm\\.venv2\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from tuyabot_llm import UseRAG\n",
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instanciando llm por primera vez\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instanciando retriever por primera vez\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mario\\Documents\\job_interviews\\2025_tuya\\tuyabot_llm\\tuyabot_llm\\models\\config_rag.py:42: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embeddings = SentenceTransformerEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
      "c:\\Users\\mario\\Documents\\job_interviews\\2025_tuya\\tuyabot_llm\\tuyabot_llm\\models\\config_rag.py:48: LangChainDeprecationWarning: The class `Chroma` was deprecated in LangChain 0.2.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-chroma package and should be used instead. To use it run `pip install -U :class:`~langchain-chroma` and import as `from :class:`~langchain_chroma import Chroma``.\n",
      "  db = Chroma(persist_directory=persistent_directory_clean, embedding_function=embeddings)\n"
     ]
    }
   ],
   "source": [
    "rag = UseRAG()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = \"¿Cuáles son los valores numéricos de la tasa de interés y póliza del producto credicompras?\"\n",
    "\n",
    "rag.generate_response(\n",
    "    question=q\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = \"¿Cuáles son los valores numéricos de la tasa de interés y póliza del producto credicompras?\"\n",
    "\n",
    "rag.generate_response(\n",
    "    question=q,\n",
    "    temperature=0.3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = \"¿Cuáles son los valores numéricos de la tasa de interés y póliza del producto credicompras?\"\n",
    "\n",
    "rag.generate_response(\n",
    "    question=q,\n",
    "    size_context=7\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo = gr.Interface(\n",
    "    fn=rag.generate_response,\n",
    "    inputs=[\n",
    "        gr.Textbox(label=\"pregunta\"),\n",
    "        gr.Slider(\n",
    "            label=\"Temperatura del modelo\",\n",
    "            minimum=0.1,\n",
    "            maximum=1,\n",
    "            value=0.2,\n",
    "            step=0.1,\n",
    "            info=\"Cuál es el grado de aleatoriedad que quieres en el modelo?\"\n",
    "        ),\n",
    "        gr.Slider(\n",
    "            label=\"Top k\",\n",
    "            minimum=5,\n",
    "            maximum=50,\n",
    "            value=10,\n",
    "            step=1,\n",
    "            info=\"Cuál top k?\"\n",
    "        ),\n",
    "        gr.Slider(\n",
    "            label=\"max_length\",\n",
    "            minimum=500,\n",
    "            maximum=2500,\n",
    "            value=2000,\n",
    "            step=100,\n",
    "            info=\"Cuál es la max_length?\"\n",
    "        ),\n",
    "        gr.Dropdown(\n",
    "            choices=[\"similarity\", \"mmr\", \"similarity_score_threshold\"],\n",
    "            value='similarity',\n",
    "            label=\"search_type\",\n",
    "            info=\"Will add more animals later!\"\n",
    "        ),\n",
    "        gr.Slider(\n",
    "            label=\"s_context\",\n",
    "            minimum=5,\n",
    "            maximum=10,\n",
    "            value=5,\n",
    "            step=1,\n",
    "            info=\"Cuál es el s_context?\"\n",
    "        ),\n",
    "    ],\n",
    "    outputs=gr.Textbox(label=\"Respuesta\"),\n",
    "    title=\"Tuya BOT\",\n",
    "    description=\"Bot con contexto de tuya, para responder todas tus preguntas financieras\",\n",
    "    # allow_flagging=\"never\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "* Running on public URL: https://c49644f71868be1dfa.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://c49644f71868be1dfa.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'temperature': 0.2, 'top_k': 10, 'max_length': 2000} {'temperature': 0.2, 'top_k': 10, 'max_length': 2000}\n",
      "{'search_type': 'similarity', 'size_context': 5} {'search_type': 'similarity', 'size_context': 5}\n",
      "Created dataset file at: .gradio\\flagged\\dataset2.csv\n",
      "{'temperature': 0.3, 'top_k': 10, 'max_length': 2000} {'temperature': 0.2, 'top_k': 10, 'max_length': 2000}\n",
      "Reinstanciando el llm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'search_type': 'mmr', 'size_context': 5} {'search_type': 'similarity', 'size_context': 5}\n",
      "Reinstanciando el retriever\n"
     ]
    }
   ],
   "source": [
    "demo.launch(share=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing server running on port: 7860\n"
     ]
    }
   ],
   "source": [
    "gr.close_all()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
